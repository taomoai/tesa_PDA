#!/usr/bin/env python3
"""
å°† backing ç±»å‹çš„ extracted JSON æ–‡ä»¶è½¬æ¢ä¸º CSV è¡¨æ ¼æ ¼å¼

è¾“å‡ºæ ¼å¼:
Backing | Property | Test Figures / Tolerances | tesa + DIN/ISO Standard

ä½¿ç”¨æ–¹æ³•:
    python tests/convert_backing_to_csv.py                    # è½¬æ¢ output/ ç›®å½•ä¸‹æ‰€æœ‰ extracted.json æ–‡ä»¶
    python tests/convert_backing_to_csv.py file1.json         # è½¬æ¢æŒ‡å®šæ–‡ä»¶
"""

import json
import csv
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional


def format_test_figures(value: Optional[str], tolerance: Optional[str], unit: Optional[str]) -> str:
    """
    æ ¼å¼åŒ–æµ‹è¯•æ•°æ®ä¸º "value Â± tolerance unit" æ ¼å¼
    
    Examples:
        format_test_figures("12", "Â±1.5", "Âµm") -> "12 Â± 1.5 Âµm"
        format_test_figures("â‰¥16", None, "N/cm") -> "â‰¥16 N/cm"
        format_test_figures("Like reference", None, None) -> "Like reference"
    """
    if not value:
        return ""
    
    parts = [value]
    
    if tolerance:
        parts.append(tolerance)
    
    if unit:
        parts.append(unit)
    
    return " ".join(parts)


def extract_backing_data(json_file: Path) -> List[Dict[str, Any]]:
    """
    ä» backing ç±»å‹çš„ extracted JSON æ–‡ä»¶ä¸­æå–è¡¨æ ¼æ•°æ®
    
    è¿”å›æ ¼å¼:
    [
        {
            'backing': 'PETDH302LWHITED12',
            'property': 'Thickness',
            'test_figures_tolerances': '12 Â± 1.5 Âµm',
            'tesa_standard': 'J0PMC002'
        },
        ...
    ]
    """
    rows = []
    
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # è·å– backing åç§°ï¼ˆä½¿ç”¨ internal_name æˆ– trade_name_of_productï¼‰
        product_info = data.get('product_info', {})
        backing_name = (
            product_info.get('internal_name') or 
            product_info.get('trade_name_of_product') or 
            product_info.get('tesa_nart') or
            json_file.stem.replace('_extracted', '')
        )
        
        # è·å– physical_and_chemical_data
        physical_data = data.get('physical_and_chemical_data', {})
        
        # å¤„ç†æ–°æ ¼å¼ï¼ˆitems å­—æ®µï¼‰å’Œæ—§æ ¼å¼ï¼ˆç›´æ¥çš„åˆ—è¡¨æˆ–å…¶ä»–å­—æ®µåï¼‰
        items = None
        if isinstance(physical_data, dict):
            # å°è¯•å¤šä¸ªå¯èƒ½çš„å­—æ®µå
            items = (
                physical_data.get('items') or 
                physical_data.get('physical_and_chemical_data') or
                physical_data.get('physicalAndChemicalData')
            )
        elif isinstance(physical_data, list):
            items = physical_data
        
        if not items:
            print(f"  âš ï¸  No physical_and_chemical_data found in {json_file.name}")
            return rows
        
        # å¤„ç†æ¯ä¸ªå±æ€§
        for item in items:
            if not isinstance(item, dict):
                continue
            
            property_name = item.get('property', '')
            if not property_name:
                continue
            
            # æ ¼å¼åŒ– tesa æµ‹è¯•æ•°æ®
            tesa_test_figures = format_test_figures(
                item.get('tesa_test_figures_value'),
                item.get('tesa_test_figures_tolerance'),
                item.get('tesa_test_figures_unit')
            )
            
            # è·å– tesa æ ‡å‡†
            tesa_standard = item.get('tesa_standard', '')
            
            # åˆ›å»ºè¡Œæ•°æ®
            row = {
                'backing': backing_name,
                'property': property_name,
                'test_figures_tolerances': tesa_test_figures,
                'tesa_standard': tesa_standard
            }
            rows.append(row)
        
        print(f"  âœ… Extracted {len(rows)} properties from {json_file.name}")
        
    except Exception as e:
        print(f"  âŒ Error processing {json_file.name}: {e}")
    
    return rows


def find_backing_files(search_dir: Path) -> List[Path]:
    """
    æŸ¥æ‰¾ backing ç±»å‹çš„ extracted JSON æ–‡ä»¶

    Args:
        search_dir: æœç´¢ç›®å½•ï¼ˆåªæœç´¢è¯¥ç›®å½•ï¼Œä¸é€’å½’å­ç›®å½•ï¼‰

    Returns:
        æ‰¾åˆ°çš„æ–‡ä»¶åˆ—è¡¨
    """
    # åªæœç´¢ output ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼Œä¸é€’å½’å­ç›®å½•
    files = sorted(search_dir.glob('*_extracted.json'))
    return files


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='Convert backing extracted JSON files to CSV format'
    )
    parser.add_argument(
        'files',
        nargs='*',
        help='Specific JSON files to convert (optional)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default=None,
        help='Output CSV file path (default: output/backing_data_summary.csv)'
    )

    args = parser.parse_args()

    output_dir = Path('output')

    # ç¡®å®šè¦å¤„ç†çš„æ–‡ä»¶
    if args.files:
        # å¤„ç†æŒ‡å®šçš„æ–‡ä»¶
        extracted_files = []
        for file_path in args.files:
            path = Path(file_path)
            if not path.exists():
                # å°è¯•åœ¨ output ç›®å½•ä¸­æŸ¥æ‰¾
                path = output_dir / file_path

            if path.exists():
                extracted_files.append(path)
            else:
                print(f"âš ï¸  File not found: {file_path}")
    else:
        # æŸ¥æ‰¾ output ç›®å½•ä¸‹çš„æ‰€æœ‰ extracted JSON æ–‡ä»¶
        extracted_files = find_backing_files(output_dir)
    
    if not extracted_files:
        print("âŒ No backing extracted JSON files found!")
        print("\nTip: Make sure you have run the backing extraction first:")
        print("  python tests/test_batch_backing_extraction.py")
        return
    
    print(f"ğŸ“ Found {len(extracted_files)} backing extracted JSON file(s)\n")
    
    # æå–æ‰€æœ‰æ•°æ®
    all_rows = []
    for json_file in extracted_files:
        print(f"Processing {json_file.name}...")
        rows = extract_backing_data(json_file)
        all_rows.extend(rows)
    
    # å†™å…¥ CSV
    if all_rows:
        # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
        if args.output:
            csv_output = Path(args.output)
        else:
            csv_output = output_dir / 'backing_data_summary.csv'
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        csv_output.parent.mkdir(parents=True, exist_ok=True)
        
        fieldnames = [
            'backing',
            'property',
            'test_figures_tolerances',
            'tesa_standard'
        ]
        
        # ä½¿ç”¨ UTF-8-BOM ç¼–ç ï¼Œè¿™æ · Excel ä¼šæ­£ç¡®è¯†åˆ«ç‰¹æ®Šå­—ç¬¦
        with open(csv_output, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            
            # å†™å…¥è¡¨å¤´ï¼ˆä½¿ç”¨æ›´å‹å¥½çš„åˆ—åï¼‰
            writer.writerow({
                'backing': 'Backing',
                'property': 'Property',
                'test_figures_tolerances': 'Test Figures / Tolerances',
                'tesa_standard': 'tesa + DIN/ISO Standard'
            })
            
            writer.writerows(all_rows)
        
        print(f"\nâœ… CSV file generated: {csv_output}")
        print(f"   Total rows: {len(all_rows)}")
        print(f"   File size: {csv_output.stat().st_size / 1024:.2f} KB")
        print(f"\nğŸ’¡ You can open this file in Excel or any spreadsheet application")
    else:
        print("\nâŒ No data extracted!")


if __name__ == '__main__':
    main()

